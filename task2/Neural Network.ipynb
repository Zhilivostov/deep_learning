{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Задание 2.1 - Нейронные сети\n",
    "\n",
    "В этом задании вы реализуете и натренируете настоящую нейроную сеть своими руками!\n",
    "\n",
    "В некотором смысле это будет расширением прошлого задания - нам нужно просто составить несколько линейных классификаторов вместе!\n",
    "\n",
    "<img src=\"https://i.redd.it/n9fgba8b0qr01.png\" alt=\"Stack_more_layers\" width=\"400px\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import load_svhn, random_split_train_val\n",
    "from gradient_check import check_layer_gradient, check_layer_param_gradient, check_model_gradient\n",
    "from layers import FullyConnectedLayer, ReLULayer\n",
    "from model import TwoLayerNet\n",
    "from trainer import Trainer, Dataset\n",
    "from optim import SGD, MomentumSGD\n",
    "from metrics import multiclass_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Загружаем данные\n",
    "\n",
    "И разделяем их на training и validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_for_neural_network(train_X, test_X):\n",
    "    train_flat = train_X.reshape(train_X.shape[0], -1).astype(np.float64) / 255.0\n",
    "    test_flat = test_X.reshape(test_X.shape[0], -1).astype(np.float64) / 255.0\n",
    "    \n",
    "    # Subtract mean\n",
    "    mean_image = np.mean(train_flat, axis = 0)\n",
    "    train_flat -= mean_image\n",
    "    test_flat -= mean_image\n",
    "    \n",
    "    return train_flat, test_flat\n",
    "    \n",
    "train_X, train_y, test_X, test_y = load_svhn(\"data\", max_train=10000, max_test=1000)    \n",
    "train_X, test_X = prepare_for_neural_network(train_X, test_X)\n",
    "# Split train into train and val\n",
    "train_X, train_y, val_X, val_y = random_split_train_val(train_X, train_y, num_val = 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Как всегда, начинаем с кирпичиков\n",
    "\n",
    "Мы будем реализовывать необходимые нам слои по очереди. Каждый слой должен реализовать:\n",
    "- прямой проход (forward pass), который генерирует выход слоя по входу и запоминает необходимые данные\n",
    "- обратный проход (backward pass), который получает градиент по выходу слоя и вычисляет градиент по входу и по параметрам\n",
    "\n",
    "Начнем с ReLU, у которого параметров нет."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient check passed!\n"
     ]
    }
   ],
   "source": [
    "# TODO: Implement ReLULayer layer in layers.py\n",
    "# Note: you'll need to copy implementation of the gradient_check function from the previous assignment\n",
    "\n",
    "X = np.array([[1,-2,3],\n",
    "              [-1, 2, 0.1]\n",
    "              ])\n",
    "\n",
    "assert check_layer_gradient(ReLULayer(), X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "А теперь реализуем полносвязный слой (fully connected layer), у которого будет два массива параметров: W (weights) и B (bias).\n",
    "\n",
    "Все параметры наши слои будут использовать для параметров специальный класс `Param`, в котором будут храниться значения параметров и градиенты этих параметров, вычисляемые во время обратного прохода.\n",
    "\n",
    "Это даст возможность аккумулировать (суммировать) градиенты из разных частей функции потерь, например, из cross-entropy loss и regularization loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient check passed!\n",
      "Gradient check passed!\n",
      "Gradient check passed!\n"
     ]
    }
   ],
   "source": [
    "# TODO: Implement FullyConnected layer forward and backward methods\n",
    "assert check_layer_gradient(FullyConnectedLayer(3, 4), X)\n",
    "# TODO: Implement storing gradients for W and B\n",
    "assert check_layer_param_gradient(FullyConnectedLayer(3, 4), X, 'W')\n",
    "assert check_layer_param_gradient(FullyConnectedLayer(3, 4), X, 'B')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Создаем нейронную сеть\n",
    "\n",
    "Теперь мы реализуем простейшую нейронную сеть с двумя полносвязным слоями и нелинейностью ReLU. Реализуйте функцию `compute_loss_and_gradients`, она должна запустить прямой и обратный проход через оба слоя для вычисления градиентов.\n",
    "\n",
    "Не забудьте реализовать очистку градиентов в начале функции."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking gradient for 0_W\n",
      "Gradient check passed!\n",
      "Checking gradient for 0_B\n",
      "Gradient check passed!\n",
      "Checking gradient for 2_W\n",
      "Gradient check passed!\n",
      "Checking gradient for 2_B\n",
      "Gradient check passed!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: In model.py, implement compute_loss_and_gradients function\n",
    "model = TwoLayerNet(n_input = train_X.shape[1], n_output = 10, hidden_layer_size = 3, reg = 0)\n",
    "loss = model.compute_loss_and_gradients(train_X[:2], train_y[:2])\n",
    "\n",
    "# TODO Now implement backward pass and aggregate all of the params\n",
    "check_model_gradient(model, train_X[:2], train_y[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь добавьте к модели регуляризацию - она должна прибавляться к loss и делать свой вклад в градиенты."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking gradient for 0_W\n",
      "Gradient check passed!\n",
      "Checking gradient for 0_B\n",
      "Gradient check passed!\n",
      "Checking gradient for 2_W\n",
      "Gradient check passed!\n",
      "Checking gradient for 2_B\n",
      "Gradient check passed!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO Now implement l2 regularization in the forward and backward pass\n",
    "model_with_reg = TwoLayerNet(n_input = train_X.shape[1], n_output = 10, hidden_layer_size = 3, reg = 1e1)\n",
    "loss_with_reg = model_with_reg.compute_loss_and_gradients(train_X[:2], train_y[:2])\n",
    "assert loss_with_reg > loss and not np.isclose(loss_with_reg, loss), \\\n",
    "    \"Loss with regularization (%2.4f) should be higher than without it (%2.4f)!\" % (loss, loss_with_reg)\n",
    "\n",
    "check_model_gradient(model_with_reg, train_X[:2], train_y[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Также реализуем функцию предсказания (вычисления значения) модели на новых данных.\n",
    "\n",
    "Какое значение точности мы ожидаем увидеть до начала тренировки?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Finally, implement predict function!\n",
    "\n",
    "# TODO: Implement predict function\n",
    "# What would be the value we expect?\n",
    "multiclass_accuracy(model_with_reg.predict(train_X[:30]), train_y[:30]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "0.1 потому что наша сеть еще не натренирована"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Допишем код для процесса тренировки\n",
    "\n",
    "Если все реализовано корректно, значение функции ошибки должно уменьшаться с каждой эпохой, пусть и медленно. Не беспокойтесь пока про validation accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.302029, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.301685, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.301851, Train accuracy: 0.148222, val accuracy: 0.140000\n",
      "Loss: 2.302623, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.302031, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.301124, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.302831, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.301638, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.302170, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.302117, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.302455, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.302807, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.302832, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.302390, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.303278, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.301772, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.302333, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.302433, Train accuracy: 0.148222, val accuracy: 0.140000\n",
      "Loss: 2.301941, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.302173, Train accuracy: 0.196667, val accuracy: 0.206000\n"
     ]
    }
   ],
   "source": [
    "model = TwoLayerNet(n_input = train_X.shape[1], n_output = 10, hidden_layer_size = 100, reg = 1e1)\n",
    "dataset = Dataset(train_X, train_y, val_X, val_y)\n",
    "trainer = Trainer(model, dataset, SGD(), learning_rate = 1e-2)\n",
    "\n",
    "# TODO Implement missing pieces in Trainer.fit function\n",
    "# You should expect loss to go down every epoch, even if it's slow\n",
    "loss_history, train_history, val_history = trainer.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x27026755e50>]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(train_history)\n",
    "plt.plot(val_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Улучшаем процесс тренировки\n",
    "\n",
    "Мы реализуем несколько ключевых оптимизаций, необходимых для тренировки современных нейросетей."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Уменьшение скорости обучения (learning rate decay)\n",
    "\n",
    "Одна из необходимых оптимизаций во время тренировки нейронных сетей - постепенное уменьшение скорости обучения по мере тренировки.\n",
    "\n",
    "Один из стандартных методов - уменьшение скорости обучения (learning rate) каждые N эпох на коэффициент d (часто называемый decay). Значения N и d, как всегда, являются гиперпараметрами и должны подбираться на основе эффективности на проверочных данных (validation data). \n",
    "\n",
    "В нашем случае N будет равным 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.275985, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.347515, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.264348, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.287890, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.253264, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.265011, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.212698, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.320777, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.302624, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.311032, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.234316, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.283390, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.353994, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.217454, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.378711, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.256101, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.309860, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.264767, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.276485, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.274562, Train accuracy: 0.196667, val accuracy: 0.206000\n"
     ]
    }
   ],
   "source": [
    "# TODO Implement learning rate decay inside Trainer.fit method\n",
    "# Decay should happen once per epoch\n",
    "\n",
    "model = TwoLayerNet(n_input = train_X.shape[1], n_output = 10, hidden_layer_size = 100, reg = 1e-1)\n",
    "dataset = Dataset(train_X, train_y, val_X, val_y)\n",
    "trainer = Trainer(model, dataset, SGD(), learning_rate_decay=0.99)\n",
    "\n",
    "initial_learning_rate = trainer.learning_rate\n",
    "loss_history, train_history, val_history = trainer.fit()\n",
    "\n",
    "assert trainer.learning_rate < initial_learning_rate, \"Learning rate should've been reduced\"\n",
    "assert trainer.learning_rate > 0.5*initial_learning_rate, \"Learning rate shouldn'tve been reduced that much!\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Накопление импульса (Momentum SGD)\n",
    "\n",
    "Другой большой класс оптимизаций - использование более эффективных методов градиентного спуска. Мы реализуем один из них - накопление импульса (Momentum SGD).\n",
    "\n",
    "Этот метод хранит скорость движения, использует градиент для ее изменения на каждом шаге, и изменяет веса пропорционально значению скорости.\n",
    "(Физическая аналогия: Вместо скорости градиенты теперь будут задавать ускорение, но будет присутствовать сила трения.)\n",
    "\n",
    "```\n",
    "velocity = momentum * velocity - learning_rate * gradient \n",
    "w = w + velocity\n",
    "```\n",
    "\n",
    "`momentum` здесь коэффициент затухания, который тоже является гиперпараметром (к счастью, для него часто есть хорошее значение по умолчанию, типичный диапазон -- 0.8-0.99).\n",
    "\n",
    "Несколько полезных ссылок, где метод разбирается более подробно:  \n",
    "http://cs231n.github.io/neural-networks-3/#sgd  \n",
    "https://distill.pub/2017/momentum/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.322051, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.308033, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.317549, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.262630, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.270323, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.308261, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.264990, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.278636, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.267083, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.279901, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.276510, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.314133, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.256404, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.295822, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.290051, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.278750, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.280567, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.255044, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.240982, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.315651, Train accuracy: 0.196667, val accuracy: 0.206000\n"
     ]
    }
   ],
   "source": [
    "# TODO: Implement MomentumSGD.update function in optim.py\n",
    "\n",
    "model = TwoLayerNet(n_input = train_X.shape[1], n_output = 10, hidden_layer_size = 100, reg = 1e-1)\n",
    "dataset = Dataset(train_X, train_y, val_X, val_y)\n",
    "trainer = Trainer(model, dataset, MomentumSGD(), learning_rate=1e-4, learning_rate_decay=0.99)\n",
    "\n",
    "# You should see even better results than before!\n",
    "loss_history, train_history, val_history = trainer.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ну что, давайте уже тренировать сеть!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Последний тест - переобучимся (overfit) на маленьком наборе данных\n",
    "\n",
    "Хороший способ проверить, все ли реализовано корректно - переобучить сеть на маленьком наборе данных.  \n",
    "Наша модель обладает достаточной мощностью, чтобы приблизить маленький набор данных идеально, поэтому мы ожидаем, что на нем мы быстро дойдем до 100% точности на тренировочном наборе. \n",
    "\n",
    "Если этого не происходит, то где-то была допущена ошибка!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.351801, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 2.319693, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 2.295926, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 2.345443, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 2.310013, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 2.326544, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 2.255641, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 2.199259, Train accuracy: 0.200000, val accuracy: 0.066667\n",
      "Loss: 2.164561, Train accuracy: 0.333333, val accuracy: 0.066667\n",
      "Loss: 2.025661, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Loss: 1.883798, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Loss: 2.263931, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Loss: 1.662918, Train accuracy: 0.333333, val accuracy: 0.000000\n",
      "Loss: 2.245522, Train accuracy: 0.333333, val accuracy: 0.000000\n",
      "Loss: 1.943906, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Loss: 1.663953, Train accuracy: 0.333333, val accuracy: 0.000000\n",
      "Loss: 2.042200, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Loss: 1.418303, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Loss: 1.519709, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Loss: 1.823944, Train accuracy: 0.466667, val accuracy: 0.000000\n",
      "Loss: 2.022291, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Loss: 1.585656, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Loss: 1.937038, Train accuracy: 0.400000, val accuracy: 0.066667\n",
      "Loss: 1.908215, Train accuracy: 0.466667, val accuracy: 0.000000\n",
      "Loss: 1.233499, Train accuracy: 0.466667, val accuracy: 0.000000\n",
      "Loss: 2.095108, Train accuracy: 0.466667, val accuracy: 0.000000\n",
      "Loss: 1.718242, Train accuracy: 0.466667, val accuracy: 0.066667\n",
      "Loss: 2.162756, Train accuracy: 0.466667, val accuracy: 0.066667\n",
      "Loss: 2.015933, Train accuracy: 0.466667, val accuracy: 0.000000\n",
      "Loss: 1.363952, Train accuracy: 0.466667, val accuracy: 0.000000\n",
      "Loss: 1.842670, Train accuracy: 0.533333, val accuracy: 0.000000\n",
      "Loss: 1.657567, Train accuracy: 0.533333, val accuracy: 0.066667\n",
      "Loss: 1.388463, Train accuracy: 0.533333, val accuracy: 0.066667\n",
      "Loss: 1.911120, Train accuracy: 0.533333, val accuracy: 0.066667\n",
      "Loss: 1.693765, Train accuracy: 0.600000, val accuracy: 0.000000\n",
      "Loss: 2.010436, Train accuracy: 0.600000, val accuracy: 0.066667\n",
      "Loss: 1.115900, Train accuracy: 0.600000, val accuracy: 0.066667\n",
      "Loss: 1.613706, Train accuracy: 0.600000, val accuracy: 0.066667\n",
      "Loss: 1.738574, Train accuracy: 0.600000, val accuracy: 0.066667\n",
      "Loss: 1.885192, Train accuracy: 0.600000, val accuracy: 0.066667\n",
      "Loss: 2.474042, Train accuracy: 0.666667, val accuracy: 0.066667\n",
      "Loss: 1.119274, Train accuracy: 0.666667, val accuracy: 0.066667\n",
      "Loss: 1.672047, Train accuracy: 0.666667, val accuracy: 0.066667\n",
      "Loss: 1.767860, Train accuracy: 0.666667, val accuracy: 0.066667\n",
      "Loss: 1.478802, Train accuracy: 0.666667, val accuracy: 0.066667\n",
      "Loss: 1.926619, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.337383, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.683186, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.660081, Train accuracy: 0.800000, val accuracy: 0.066667\n",
      "Loss: 1.401881, Train accuracy: 0.733333, val accuracy: 0.133333\n",
      "Loss: 1.635264, Train accuracy: 0.733333, val accuracy: 0.000000\n",
      "Loss: 1.635617, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.622938, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.854111, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.556636, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.634732, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.076198, Train accuracy: 0.666667, val accuracy: 0.000000\n",
      "Loss: 1.007559, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.531114, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.041336, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 2.022564, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.647379, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.369538, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.379903, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.986917, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.318972, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.283966, Train accuracy: 0.733333, val accuracy: 0.000000\n",
      "Loss: 0.936269, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.196061, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.739352, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.634901, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.201189, Train accuracy: 0.733333, val accuracy: 0.000000\n",
      "Loss: 1.582981, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.742143, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.293135, Train accuracy: 0.733333, val accuracy: 0.066667\n",
      "Loss: 1.748190, Train accuracy: 0.800000, val accuracy: 0.066667\n",
      "Loss: 1.976545, Train accuracy: 0.800000, val accuracy: 0.000000\n",
      "Loss: 1.357876, Train accuracy: 0.800000, val accuracy: 0.066667\n",
      "Loss: 0.992895, Train accuracy: 0.800000, val accuracy: 0.066667\n",
      "Loss: 1.602046, Train accuracy: 0.800000, val accuracy: 0.066667\n",
      "Loss: 1.602167, Train accuracy: 0.866667, val accuracy: 0.066667\n",
      "Loss: 1.173057, Train accuracy: 0.866667, val accuracy: 0.066667\n",
      "Loss: 1.312798, Train accuracy: 0.866667, val accuracy: 0.000000\n",
      "Loss: 1.564551, Train accuracy: 0.866667, val accuracy: 0.000000\n",
      "Loss: 0.961713, Train accuracy: 0.866667, val accuracy: 0.066667\n",
      "Loss: 1.274091, Train accuracy: 0.866667, val accuracy: 0.066667\n",
      "Loss: 1.304703, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 0.958926, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 1.377168, Train accuracy: 0.866667, val accuracy: 0.066667\n",
      "Loss: 1.657193, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 1.389767, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 1.576803, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 1.556738, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 1.175409, Train accuracy: 0.933333, val accuracy: 0.000000\n",
      "Loss: 1.322616, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 1.251510, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 1.060407, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 1.661861, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 1.227308, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 1.597969, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 1.887250, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 1.338688, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 1.842966, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 1.160604, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 1.347215, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 1.223119, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 1.436648, Train accuracy: 0.933333, val accuracy: 0.000000\n",
      "Loss: 1.535320, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 1.249121, Train accuracy: 0.933333, val accuracy: 0.066667\n",
      "Loss: 1.248964, Train accuracy: 0.933333, val accuracy: 0.000000\n",
      "Loss: 1.549803, Train accuracy: 1.000000, val accuracy: 0.066667\n",
      "Loss: 1.259687, Train accuracy: 0.933333, val accuracy: 0.000000\n",
      "Loss: 1.097239, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.324286, Train accuracy: 0.933333, val accuracy: 0.000000\n",
      "Loss: 1.315431, Train accuracy: 0.933333, val accuracy: 0.000000\n",
      "Loss: 1.420746, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.443017, Train accuracy: 0.933333, val accuracy: 0.000000\n",
      "Loss: 1.301618, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.533658, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.607993, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.239065, Train accuracy: 0.933333, val accuracy: 0.000000\n",
      "Loss: 1.649177, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.174445, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.602848, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.363682, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.160640, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.197888, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.126413, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.008120, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.643235, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.592807, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.412599, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.212850, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.196541, Train accuracy: 0.933333, val accuracy: 0.000000\n",
      "Loss: 1.280346, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.403204, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.229377, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.400568, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.391042, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.102808, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.445285, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.406323, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.219193, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.449330, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.304464, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.494726, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.327706, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.361608, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.460816, Train accuracy: 1.000000, val accuracy: 0.000000\n",
      "Loss: 1.424061, Train accuracy: 1.000000, val accuracy: 0.000000\n"
     ]
    }
   ],
   "source": [
    "data_size = 15\n",
    "model = TwoLayerNet(n_input = train_X.shape[1], n_output = 10, hidden_layer_size = 100, reg = 1e-1)\n",
    "dataset = Dataset(train_X[:data_size], train_y[:data_size], val_X[:data_size], val_y[:data_size])\n",
    "trainer = Trainer(model, dataset, SGD(), learning_rate=1e-1, num_epochs=150, batch_size=5)\n",
    "\n",
    "# You should expect this to reach 1.0 training accuracy \n",
    "loss_history, train_history, val_history = trainer.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь найдем гипепараметры, для которых этот процесс сходится быстрее.\n",
    "Если все реализовано корректно, то существуют параметры, при которых процесс сходится в **20** эпох или еще быстрее.\n",
    "Найдите их!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.331042, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 2.319385, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 2.283704, Train accuracy: 0.200000, val accuracy: 0.133333\n",
      "Loss: 2.309925, Train accuracy: 0.266667, val accuracy: 0.000000\n",
      "Loss: 2.285989, Train accuracy: 0.266667, val accuracy: 0.000000\n",
      "Loss: 2.352220, Train accuracy: 0.266667, val accuracy: 0.000000\n",
      "Loss: 2.261306, Train accuracy: 0.266667, val accuracy: 0.000000\n",
      "Loss: 2.287292, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Loss: 2.315104, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Loss: 2.268513, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Loss: 2.242892, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Loss: 2.047102, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Loss: 1.901234, Train accuracy: 0.333333, val accuracy: 0.000000\n",
      "Loss: 1.948076, Train accuracy: 0.333333, val accuracy: 0.000000\n",
      "Loss: 1.740618, Train accuracy: 0.333333, val accuracy: 0.000000\n",
      "Loss: 1.914006, Train accuracy: 0.333333, val accuracy: 0.000000\n",
      "Loss: 1.841368, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Loss: 1.927281, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Loss: 2.294955, Train accuracy: 0.400000, val accuracy: 0.000000\n",
      "Loss: 1.815748, Train accuracy: 0.400000, val accuracy: 0.000000\n"
     ]
    }
   ],
   "source": [
    "# Now, tweak some hyper parameters and make it train to 1.0 accuracy in 20 epochs or less\n",
    "\n",
    "model = TwoLayerNet(n_input = train_X.shape[1], n_output = 10, hidden_layer_size = 100, reg = 1e-1)\n",
    "dataset = Dataset(train_X[:data_size], train_y[:data_size], val_X[:data_size], val_y[:data_size])\n",
    "# TODO: Change any hyperparamers or optimizators to reach training accuracy in 20 epochs\n",
    "trainer = Trainer(model, dataset, SGD(), learning_rate=1e-1, num_epochs=20, batch_size=5)\n",
    "\n",
    "loss_history, train_history, val_history = trainer.fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Да, всё корректно"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Итак, основное мероприятие!\n",
    "\n",
    "Натренируйте лучшую нейросеть! Можно добавлять и изменять параметры, менять количество нейронов в слоях сети и как угодно экспериментировать. \n",
    "\n",
    "Добейтесь точности лучше **60%** на validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 2.124864, Train accuracy: 0.311778, val accuracy: 0.303000\n",
      "Loss: 1.891299, Train accuracy: 0.459889, val accuracy: 0.468000\n",
      "Loss: 1.587045, Train accuracy: 0.493111, val accuracy: 0.466000\n",
      "Loss: 1.560987, Train accuracy: 0.578556, val accuracy: 0.583000\n",
      "Loss: 1.667837, Train accuracy: 0.606111, val accuracy: 0.571000\n",
      "Loss: 1.780312, Train accuracy: 0.615667, val accuracy: 0.612000\n",
      "Loss: 1.301897, Train accuracy: 0.625000, val accuracy: 0.607000\n",
      "Loss: 1.545656, Train accuracy: 0.646889, val accuracy: 0.640000\n",
      "Loss: 1.490220, Train accuracy: 0.644444, val accuracy: 0.635000\n",
      "Loss: 1.328785, Train accuracy: 0.610000, val accuracy: 0.581000\n",
      "Loss: 2.058270, Train accuracy: 0.587778, val accuracy: 0.556000\n",
      "Loss: 1.708391, Train accuracy: 0.560333, val accuracy: 0.535000\n",
      "Loss: 1.617518, Train accuracy: 0.650222, val accuracy: 0.616000\n",
      "Loss: 1.135739, Train accuracy: 0.651556, val accuracy: 0.640000\n",
      "Loss: 1.840367, Train accuracy: 0.594222, val accuracy: 0.576000\n",
      "Loss: 2.245572, Train accuracy: 0.634889, val accuracy: 0.591000\n",
      "Loss: 2.221219, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 1.718795, Train accuracy: 0.344778, val accuracy: 0.331000\n",
      "Loss: 1.343144, Train accuracy: 0.496000, val accuracy: 0.505000\n",
      "Loss: 1.511885, Train accuracy: 0.560556, val accuracy: 0.570000\n",
      "Loss: 1.323018, Train accuracy: 0.595333, val accuracy: 0.590000\n",
      "Loss: 1.011145, Train accuracy: 0.654778, val accuracy: 0.635000\n",
      "Loss: 1.277060, Train accuracy: 0.693333, val accuracy: 0.661000\n",
      "Loss: 1.636296, Train accuracy: 0.655111, val accuracy: 0.616000\n",
      "Loss: 1.436697, Train accuracy: 0.679556, val accuracy: 0.667000\n",
      "Loss: 1.121176, Train accuracy: 0.694889, val accuracy: 0.654000\n",
      "Loss: 1.185329, Train accuracy: 0.721667, val accuracy: 0.677000\n",
      "Loss: 1.424162, Train accuracy: 0.681000, val accuracy: 0.658000\n",
      "Loss: 1.365185, Train accuracy: 0.692000, val accuracy: 0.671000\n",
      "Loss: 1.385571, Train accuracy: 0.731222, val accuracy: 0.684000\n",
      "Loss: 1.262553, Train accuracy: 0.721667, val accuracy: 0.672000\n",
      "Loss: 1.052408, Train accuracy: 0.689222, val accuracy: 0.663000\n",
      "Loss: 2.260337, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.153297, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 1.995062, Train accuracy: 0.274222, val accuracy: 0.276000\n",
      "Loss: 1.926956, Train accuracy: 0.394444, val accuracy: 0.399000\n",
      "Loss: 1.505528, Train accuracy: 0.499778, val accuracy: 0.497000\n",
      "Loss: 1.467922, Train accuracy: 0.537444, val accuracy: 0.546000\n",
      "Loss: 1.212926, Train accuracy: 0.566111, val accuracy: 0.556000\n",
      "Loss: 1.198342, Train accuracy: 0.646222, val accuracy: 0.625000\n",
      "Loss: 1.450448, Train accuracy: 0.637333, val accuracy: 0.644000\n",
      "Loss: 1.087769, Train accuracy: 0.688000, val accuracy: 0.668000\n",
      "Loss: 1.221956, Train accuracy: 0.684000, val accuracy: 0.677000\n",
      "Loss: 1.548521, Train accuracy: 0.681778, val accuracy: 0.659000\n",
      "Loss: 1.070340, Train accuracy: 0.699556, val accuracy: 0.676000\n",
      "Loss: 1.504266, Train accuracy: 0.711778, val accuracy: 0.691000\n",
      "Loss: 1.162071, Train accuracy: 0.719111, val accuracy: 0.681000\n",
      "Loss: 1.065253, Train accuracy: 0.681222, val accuracy: 0.665000\n",
      "Loss: 2.004601, Train accuracy: 0.334667, val accuracy: 0.328000\n",
      "Loss: 2.124159, Train accuracy: 0.541333, val accuracy: 0.523000\n",
      "Loss: 1.267109, Train accuracy: 0.580667, val accuracy: 0.567000\n",
      "Loss: 1.844225, Train accuracy: 0.565333, val accuracy: 0.567000\n",
      "Loss: 1.594773, Train accuracy: 0.645667, val accuracy: 0.616000\n",
      "Loss: 1.363824, Train accuracy: 0.621556, val accuracy: 0.613000\n",
      "Loss: 1.413489, Train accuracy: 0.655889, val accuracy: 0.618000\n",
      "Loss: 1.310284, Train accuracy: 0.642778, val accuracy: 0.595000\n",
      "Loss: 1.649588, Train accuracy: 0.629111, val accuracy: 0.621000\n",
      "Loss: 1.749381, Train accuracy: 0.633667, val accuracy: 0.592000\n",
      "Loss: 1.644832, Train accuracy: 0.639556, val accuracy: 0.623000\n",
      "Loss: 1.349913, Train accuracy: 0.678556, val accuracy: 0.646000\n",
      "Loss: 2.042503, Train accuracy: 0.583000, val accuracy: 0.580000\n",
      "Loss: 2.513000, Train accuracy: 0.635111, val accuracy: 0.616000\n",
      "Loss: 1.652591, Train accuracy: 0.646444, val accuracy: 0.621000\n",
      "Loss: 1.333108, Train accuracy: 0.668111, val accuracy: 0.635000\n",
      "Loss: 2.225539, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 1.642442, Train accuracy: 0.346111, val accuracy: 0.361000\n",
      "Loss: 1.207548, Train accuracy: 0.509222, val accuracy: 0.480000\n",
      "Loss: 1.391454, Train accuracy: 0.583222, val accuracy: 0.566000\n",
      "Loss: 1.569303, Train accuracy: 0.614889, val accuracy: 0.599000\n",
      "Loss: 1.609574, Train accuracy: 0.655667, val accuracy: 0.614000\n",
      "Loss: 1.314762, Train accuracy: 0.674222, val accuracy: 0.645000\n",
      "Loss: 1.164584, Train accuracy: 0.646222, val accuracy: 0.607000\n",
      "Loss: 0.964137, Train accuracy: 0.715000, val accuracy: 0.673000\n",
      "Loss: 1.341919, Train accuracy: 0.683222, val accuracy: 0.672000\n",
      "Loss: 1.147781, Train accuracy: 0.706667, val accuracy: 0.657000\n",
      "Loss: 1.008706, Train accuracy: 0.704778, val accuracy: 0.657000\n",
      "Loss: 1.044754, Train accuracy: 0.694778, val accuracy: 0.640000\n",
      "Loss: 1.602036, Train accuracy: 0.724556, val accuracy: 0.676000\n",
      "Loss: 1.225089, Train accuracy: 0.734667, val accuracy: 0.671000\n",
      "Loss: 1.109136, Train accuracy: 0.709889, val accuracy: 0.650000\n",
      "Loss: 2.358042, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.112505, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 1.835165, Train accuracy: 0.317000, val accuracy: 0.317000\n",
      "Loss: 1.766207, Train accuracy: 0.436889, val accuracy: 0.434000\n",
      "Loss: 1.739204, Train accuracy: 0.529889, val accuracy: 0.519000\n",
      "Loss: 1.313834, Train accuracy: 0.601333, val accuracy: 0.588000\n",
      "Loss: 1.337048, Train accuracy: 0.609778, val accuracy: 0.593000\n",
      "Loss: 1.314302, Train accuracy: 0.628444, val accuracy: 0.607000\n",
      "Loss: 1.352211, Train accuracy: 0.691556, val accuracy: 0.673000\n",
      "Loss: 1.275340, Train accuracy: 0.709667, val accuracy: 0.666000\n",
      "Loss: 1.270251, Train accuracy: 0.700889, val accuracy: 0.664000\n",
      "Loss: 0.817767, Train accuracy: 0.723444, val accuracy: 0.680000\n",
      "Loss: 1.493976, Train accuracy: 0.714111, val accuracy: 0.675000\n",
      "Loss: 0.958353, Train accuracy: 0.705222, val accuracy: 0.659000\n",
      "Loss: 1.402005, Train accuracy: 0.692000, val accuracy: 0.656000\n",
      "Loss: 1.264103, Train accuracy: 0.735667, val accuracy: 0.695000\n",
      "Loss: 1.979055, Train accuracy: 0.379778, val accuracy: 0.373000\n",
      "Loss: 1.773108, Train accuracy: 0.516222, val accuracy: 0.516000\n",
      "Loss: 1.900492, Train accuracy: 0.558000, val accuracy: 0.549000\n",
      "Loss: 1.713682, Train accuracy: 0.599333, val accuracy: 0.586000\n",
      "Loss: 1.459028, Train accuracy: 0.616778, val accuracy: 0.628000\n",
      "Loss: 1.529027, Train accuracy: 0.639000, val accuracy: 0.596000\n",
      "Loss: 2.022872, Train accuracy: 0.650111, val accuracy: 0.631000\n",
      "Loss: 1.502861, Train accuracy: 0.657556, val accuracy: 0.627000\n",
      "Loss: 1.543535, Train accuracy: 0.633222, val accuracy: 0.622000\n",
      "Loss: 1.727566, Train accuracy: 0.618444, val accuracy: 0.601000\n",
      "Loss: 1.513861, Train accuracy: 0.601444, val accuracy: 0.601000\n",
      "Loss: 1.513435, Train accuracy: 0.612222, val accuracy: 0.611000\n",
      "Loss: 1.451171, Train accuracy: 0.657556, val accuracy: 0.607000\n",
      "Loss: 1.830828, Train accuracy: 0.608889, val accuracy: 0.573000\n",
      "Loss: 1.489129, Train accuracy: 0.651222, val accuracy: 0.593000\n",
      "Loss: 1.870857, Train accuracy: 0.700333, val accuracy: 0.661000\n",
      "Loss: 2.163215, Train accuracy: 0.209444, val accuracy: 0.212000\n",
      "Loss: 1.652769, Train accuracy: 0.432000, val accuracy: 0.406000\n",
      "Loss: 1.458230, Train accuracy: 0.594000, val accuracy: 0.581000\n",
      "Loss: 1.837317, Train accuracy: 0.643778, val accuracy: 0.638000\n",
      "Loss: 1.583933, Train accuracy: 0.645111, val accuracy: 0.612000\n",
      "Loss: 1.153165, Train accuracy: 0.688778, val accuracy: 0.672000\n",
      "Loss: 1.150312, Train accuracy: 0.682889, val accuracy: 0.637000\n",
      "Loss: 1.441581, Train accuracy: 0.689667, val accuracy: 0.645000\n",
      "Loss: 0.946555, Train accuracy: 0.705333, val accuracy: 0.654000\n",
      "Loss: 1.050924, Train accuracy: 0.672444, val accuracy: 0.650000\n",
      "Loss: 1.232553, Train accuracy: 0.716000, val accuracy: 0.668000\n",
      "Loss: 1.647913, Train accuracy: 0.750111, val accuracy: 0.681000\n",
      "Loss: 1.205063, Train accuracy: 0.728111, val accuracy: 0.687000\n",
      "Loss: 1.228168, Train accuracy: 0.743111, val accuracy: 0.695000\n",
      "Loss: 0.911038, Train accuracy: 0.757667, val accuracy: 0.687000\n",
      "Loss: 1.238191, Train accuracy: 0.764778, val accuracy: 0.700000\n",
      "Loss: 2.220309, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.130289, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.093156, Train accuracy: 0.301111, val accuracy: 0.300000\n",
      "Loss: 1.802511, Train accuracy: 0.452000, val accuracy: 0.437000\n",
      "Loss: 1.570638, Train accuracy: 0.543444, val accuracy: 0.537000\n",
      "Loss: 1.596461, Train accuracy: 0.615111, val accuracy: 0.590000\n",
      "Loss: 1.361305, Train accuracy: 0.654222, val accuracy: 0.647000\n",
      "Loss: 1.035150, Train accuracy: 0.650000, val accuracy: 0.624000\n",
      "Loss: 0.851821, Train accuracy: 0.686778, val accuracy: 0.673000\n",
      "Loss: 1.189142, Train accuracy: 0.687333, val accuracy: 0.671000\n",
      "Loss: 1.028555, Train accuracy: 0.728222, val accuracy: 0.698000\n",
      "Loss: 1.042584, Train accuracy: 0.738778, val accuracy: 0.708000\n",
      "Loss: 0.995584, Train accuracy: 0.756222, val accuracy: 0.709000\n",
      "Loss: 0.985726, Train accuracy: 0.742778, val accuracy: 0.689000\n",
      "Loss: 0.777006, Train accuracy: 0.734889, val accuracy: 0.689000\n",
      "Loss: 1.094506, Train accuracy: 0.757000, val accuracy: 0.711000\n",
      "Loss: 1.743013, Train accuracy: 0.338111, val accuracy: 0.352000\n",
      "Loss: 1.528323, Train accuracy: 0.510444, val accuracy: 0.500000\n",
      "Loss: 1.764368, Train accuracy: 0.593222, val accuracy: 0.576000\n",
      "Loss: 1.323237, Train accuracy: 0.628889, val accuracy: 0.616000\n",
      "Loss: 1.126894, Train accuracy: 0.628444, val accuracy: 0.577000\n",
      "Loss: 1.142703, Train accuracy: 0.673000, val accuracy: 0.632000\n",
      "Loss: 1.218872, Train accuracy: 0.652667, val accuracy: 0.625000\n",
      "Loss: 0.610366, Train accuracy: 0.668000, val accuracy: 0.634000\n",
      "Loss: 1.285167, Train accuracy: 0.682222, val accuracy: 0.635000\n",
      "Loss: 0.643602, Train accuracy: 0.690222, val accuracy: 0.657000\n",
      "Loss: 0.886124, Train accuracy: 0.675444, val accuracy: 0.628000\n",
      "Loss: 1.253986, Train accuracy: 0.696000, val accuracy: 0.655000\n",
      "Loss: 0.720572, Train accuracy: 0.719111, val accuracy: 0.667000\n",
      "Loss: 1.145152, Train accuracy: 0.693778, val accuracy: 0.635000\n",
      "Loss: 1.061520, Train accuracy: 0.706444, val accuracy: 0.669000\n",
      "Loss: 1.200518, Train accuracy: 0.709889, val accuracy: 0.655000\n",
      "Loss: 2.241901, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 1.815168, Train accuracy: 0.355000, val accuracy: 0.356000\n",
      "Loss: 1.276177, Train accuracy: 0.503333, val accuracy: 0.513000\n",
      "Loss: 1.195907, Train accuracy: 0.603667, val accuracy: 0.585000\n",
      "Loss: 1.354659, Train accuracy: 0.610000, val accuracy: 0.595000\n",
      "Loss: 1.088636, Train accuracy: 0.661111, val accuracy: 0.631000\n",
      "Loss: 1.002709, Train accuracy: 0.665222, val accuracy: 0.640000\n",
      "Loss: 1.000836, Train accuracy: 0.713000, val accuracy: 0.665000\n",
      "Loss: 1.237600, Train accuracy: 0.692222, val accuracy: 0.650000\n",
      "Loss: 0.664409, Train accuracy: 0.733889, val accuracy: 0.695000\n",
      "Loss: 0.915726, Train accuracy: 0.704000, val accuracy: 0.631000\n",
      "Loss: 0.696275, Train accuracy: 0.749778, val accuracy: 0.679000\n",
      "Loss: 0.557949, Train accuracy: 0.738556, val accuracy: 0.679000\n",
      "Loss: 0.596168, Train accuracy: 0.761000, val accuracy: 0.690000\n",
      "Loss: 1.014314, Train accuracy: 0.748667, val accuracy: 0.667000\n",
      "Loss: 1.040345, Train accuracy: 0.753333, val accuracy: 0.681000\n",
      "Loss: 2.358243, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.266611, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.181000, Train accuracy: 0.272000, val accuracy: 0.279000\n",
      "Loss: 1.355221, Train accuracy: 0.412778, val accuracy: 0.425000\n",
      "Loss: 1.544414, Train accuracy: 0.548333, val accuracy: 0.540000\n",
      "Loss: 1.265284, Train accuracy: 0.599889, val accuracy: 0.587000\n",
      "Loss: 1.363165, Train accuracy: 0.603444, val accuracy: 0.593000\n",
      "Loss: 1.167296, Train accuracy: 0.616444, val accuracy: 0.605000\n",
      "Loss: 1.014181, Train accuracy: 0.674444, val accuracy: 0.645000\n",
      "Loss: 1.392709, Train accuracy: 0.661333, val accuracy: 0.641000\n",
      "Loss: 1.226926, Train accuracy: 0.690667, val accuracy: 0.670000\n",
      "Loss: 1.452374, Train accuracy: 0.687333, val accuracy: 0.662000\n",
      "Loss: 0.814840, Train accuracy: 0.741889, val accuracy: 0.714000\n",
      "Loss: 1.038086, Train accuracy: 0.730889, val accuracy: 0.689000\n",
      "Loss: 0.602421, Train accuracy: 0.759333, val accuracy: 0.698000\n",
      "Loss: 1.112078, Train accuracy: 0.752444, val accuracy: 0.685000\n",
      "Loss: 1.745324, Train accuracy: 0.370444, val accuracy: 0.368000\n",
      "Loss: 1.739277, Train accuracy: 0.547111, val accuracy: 0.551000\n",
      "Loss: 1.162107, Train accuracy: 0.599667, val accuracy: 0.607000\n",
      "Loss: 1.169247, Train accuracy: 0.627667, val accuracy: 0.551000\n",
      "Loss: 1.384234, Train accuracy: 0.665556, val accuracy: 0.631000\n",
      "Loss: 2.146238, Train accuracy: 0.678222, val accuracy: 0.633000\n",
      "Loss: 1.361933, Train accuracy: 0.698222, val accuracy: 0.655000\n",
      "Loss: 0.995585, Train accuracy: 0.704222, val accuracy: 0.644000\n",
      "Loss: 0.728742, Train accuracy: 0.736222, val accuracy: 0.684000\n",
      "Loss: 0.728529, Train accuracy: 0.704556, val accuracy: 0.647000\n",
      "Loss: 1.174578, Train accuracy: 0.699778, val accuracy: 0.640000\n",
      "Loss: 0.850765, Train accuracy: 0.724889, val accuracy: 0.645000\n",
      "Loss: 0.851993, Train accuracy: 0.748444, val accuracy: 0.677000\n",
      "Loss: 1.162952, Train accuracy: 0.745000, val accuracy: 0.685000\n",
      "Loss: 0.616585, Train accuracy: 0.764333, val accuracy: 0.692000\n",
      "Loss: 1.424680, Train accuracy: 0.751889, val accuracy: 0.656000\n",
      "Loss: 2.220024, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 1.843376, Train accuracy: 0.425000, val accuracy: 0.426000\n",
      "Loss: 1.302864, Train accuracy: 0.564667, val accuracy: 0.544000\n",
      "Loss: 1.127766, Train accuracy: 0.602667, val accuracy: 0.572000\n",
      "Loss: 1.542163, Train accuracy: 0.631000, val accuracy: 0.617000\n",
      "Loss: 1.416224, Train accuracy: 0.694222, val accuracy: 0.652000\n",
      "Loss: 0.848852, Train accuracy: 0.699778, val accuracy: 0.663000\n",
      "Loss: 0.937679, Train accuracy: 0.698556, val accuracy: 0.656000\n",
      "Loss: 1.176675, Train accuracy: 0.731889, val accuracy: 0.668000\n",
      "Loss: 0.821582, Train accuracy: 0.763889, val accuracy: 0.698000\n",
      "Loss: 0.695568, Train accuracy: 0.761333, val accuracy: 0.688000\n",
      "Loss: 0.492320, Train accuracy: 0.762222, val accuracy: 0.685000\n",
      "Loss: 0.660045, Train accuracy: 0.779111, val accuracy: 0.707000\n",
      "Loss: 0.604184, Train accuracy: 0.764556, val accuracy: 0.692000\n",
      "Loss: 0.570739, Train accuracy: 0.801222, val accuracy: 0.708000\n",
      "Loss: 0.778057, Train accuracy: 0.792556, val accuracy: 0.708000\n",
      "Loss: 2.236143, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.252299, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 1.901094, Train accuracy: 0.295000, val accuracy: 0.298000\n",
      "Loss: 1.737656, Train accuracy: 0.458000, val accuracy: 0.454000\n",
      "Loss: 1.337903, Train accuracy: 0.550889, val accuracy: 0.539000\n",
      "Loss: 1.046966, Train accuracy: 0.612667, val accuracy: 0.608000\n",
      "Loss: 1.097688, Train accuracy: 0.629222, val accuracy: 0.626000\n",
      "Loss: 1.374915, Train accuracy: 0.660444, val accuracy: 0.632000\n",
      "Loss: 1.141491, Train accuracy: 0.707111, val accuracy: 0.675000\n",
      "Loss: 1.015943, Train accuracy: 0.690111, val accuracy: 0.659000\n",
      "Loss: 0.724493, Train accuracy: 0.707111, val accuracy: 0.659000\n",
      "Loss: 1.012050, Train accuracy: 0.735000, val accuracy: 0.681000\n",
      "Loss: 0.745571, Train accuracy: 0.755667, val accuracy: 0.711000\n",
      "Loss: 0.558294, Train accuracy: 0.771000, val accuracy: 0.701000\n",
      "Loss: 0.717697, Train accuracy: 0.749000, val accuracy: 0.680000\n",
      "Loss: 0.768963, Train accuracy: 0.784556, val accuracy: 0.701000\n",
      "Loss: 1.831418, Train accuracy: 0.395222, val accuracy: 0.392000\n",
      "Loss: 1.523698, Train accuracy: 0.505778, val accuracy: 0.471000\n",
      "Loss: 1.038323, Train accuracy: 0.588778, val accuracy: 0.571000\n",
      "Loss: 0.751810, Train accuracy: 0.575222, val accuracy: 0.532000\n",
      "Loss: 1.295929, Train accuracy: 0.669111, val accuracy: 0.634000\n",
      "Loss: 0.993400, Train accuracy: 0.684556, val accuracy: 0.623000\n",
      "Loss: 1.504692, Train accuracy: 0.664333, val accuracy: 0.628000\n",
      "Loss: 1.537886, Train accuracy: 0.687444, val accuracy: 0.638000\n",
      "Loss: 0.997609, Train accuracy: 0.675778, val accuracy: 0.615000\n",
      "Loss: 0.857454, Train accuracy: 0.734556, val accuracy: 0.654000\n",
      "Loss: 1.093033, Train accuracy: 0.708556, val accuracy: 0.662000\n",
      "Loss: 0.715437, Train accuracy: 0.742444, val accuracy: 0.644000\n",
      "Loss: 1.118588, Train accuracy: 0.714889, val accuracy: 0.626000\n",
      "Loss: 0.793570, Train accuracy: 0.658667, val accuracy: 0.597000\n",
      "Loss: 0.980145, Train accuracy: 0.758667, val accuracy: 0.682000\n",
      "Loss: 0.854400, Train accuracy: 0.791111, val accuracy: 0.688000\n",
      "Loss: 2.349286, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 1.864202, Train accuracy: 0.440444, val accuracy: 0.435000\n",
      "Loss: 1.405003, Train accuracy: 0.530444, val accuracy: 0.525000\n",
      "Loss: 0.827759, Train accuracy: 0.658333, val accuracy: 0.642000\n",
      "Loss: 1.269947, Train accuracy: 0.658444, val accuracy: 0.627000\n",
      "Loss: 0.975296, Train accuracy: 0.683000, val accuracy: 0.654000\n",
      "Loss: 1.124484, Train accuracy: 0.703667, val accuracy: 0.666000\n",
      "Loss: 0.873995, Train accuracy: 0.756222, val accuracy: 0.708000\n",
      "Loss: 0.576664, Train accuracy: 0.765000, val accuracy: 0.714000\n",
      "Loss: 0.862978, Train accuracy: 0.732000, val accuracy: 0.673000\n",
      "Loss: 1.250959, Train accuracy: 0.790667, val accuracy: 0.690000\n",
      "Loss: 0.708123, Train accuracy: 0.799000, val accuracy: 0.711000\n",
      "Loss: 0.882992, Train accuracy: 0.775778, val accuracy: 0.684000\n",
      "Loss: 1.302481, Train accuracy: 0.782222, val accuracy: 0.699000\n",
      "Loss: 0.635084, Train accuracy: 0.811000, val accuracy: 0.709000\n",
      "Loss: 0.818509, Train accuracy: 0.844889, val accuracy: 0.735000\n",
      "Loss: 2.322176, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.142013, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 1.980302, Train accuracy: 0.336333, val accuracy: 0.337000\n",
      "Loss: 1.319314, Train accuracy: 0.491556, val accuracy: 0.504000\n",
      "Loss: 1.531853, Train accuracy: 0.586222, val accuracy: 0.588000\n",
      "Loss: 1.172934, Train accuracy: 0.629000, val accuracy: 0.638000\n",
      "Loss: 1.610676, Train accuracy: 0.607667, val accuracy: 0.598000\n",
      "Loss: 1.056910, Train accuracy: 0.691333, val accuracy: 0.669000\n",
      "Loss: 0.809605, Train accuracy: 0.690000, val accuracy: 0.662000\n",
      "Loss: 1.091057, Train accuracy: 0.731000, val accuracy: 0.685000\n",
      "Loss: 1.313801, Train accuracy: 0.754000, val accuracy: 0.698000\n",
      "Loss: 1.504541, Train accuracy: 0.721222, val accuracy: 0.665000\n",
      "Loss: 1.099655, Train accuracy: 0.754000, val accuracy: 0.702000\n",
      "Loss: 0.880320, Train accuracy: 0.780889, val accuracy: 0.713000\n",
      "Loss: 0.939175, Train accuracy: 0.784333, val accuracy: 0.707000\n",
      "Loss: 0.741404, Train accuracy: 0.789556, val accuracy: 0.720000\n",
      "Loss: 2.157312, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.285035, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.157203, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 1.974379, Train accuracy: 0.240111, val accuracy: 0.244000\n",
      "Loss: 1.964649, Train accuracy: 0.276444, val accuracy: 0.276000\n",
      "Loss: 2.078004, Train accuracy: 0.312778, val accuracy: 0.319000\n",
      "Loss: 1.986610, Train accuracy: 0.375889, val accuracy: 0.373000\n",
      "Loss: 1.784160, Train accuracy: 0.414444, val accuracy: 0.403000\n",
      "Loss: 1.556768, Train accuracy: 0.447889, val accuracy: 0.438000\n",
      "Loss: 1.804037, Train accuracy: 0.517556, val accuracy: 0.510000\n",
      "Loss: 1.837878, Train accuracy: 0.560778, val accuracy: 0.541000\n",
      "Loss: 1.123814, Train accuracy: 0.603667, val accuracy: 0.570000\n",
      "Loss: 1.245436, Train accuracy: 0.624444, val accuracy: 0.610000\n",
      "Loss: 1.395780, Train accuracy: 0.661667, val accuracy: 0.630000\n",
      "Loss: 0.973212, Train accuracy: 0.684667, val accuracy: 0.653000\n",
      "Loss: 1.110066, Train accuracy: 0.693556, val accuracy: 0.666000\n",
      "Loss: 2.237906, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.223507, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.255366, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.192240, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.244383, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.237110, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.146347, Train accuracy: 0.200000, val accuracy: 0.210000\n",
      "Loss: 2.116739, Train accuracy: 0.250889, val accuracy: 0.251000\n",
      "Loss: 2.058897, Train accuracy: 0.263889, val accuracy: 0.259000\n",
      "Loss: 2.308932, Train accuracy: 0.284000, val accuracy: 0.285000\n",
      "Loss: 2.048462, Train accuracy: 0.318222, val accuracy: 0.320000\n",
      "Loss: 1.866240, Train accuracy: 0.350889, val accuracy: 0.346000\n",
      "Loss: 1.724160, Train accuracy: 0.386111, val accuracy: 0.382000\n",
      "Loss: 1.732337, Train accuracy: 0.411333, val accuracy: 0.410000\n",
      "Loss: 1.748898, Train accuracy: 0.438556, val accuracy: 0.443000\n",
      "Loss: 1.706289, Train accuracy: 0.470444, val accuracy: 0.472000\n",
      "Loss: 2.287069, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.249162, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.231531, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.216845, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.138656, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.175703, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.226905, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.277027, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.172733, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.126423, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.267662, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.108328, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.119300, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.269053, Train accuracy: 0.214556, val accuracy: 0.222000\n",
      "Loss: 2.032670, Train accuracy: 0.235444, val accuracy: 0.241000\n",
      "Loss: 2.119269, Train accuracy: 0.258667, val accuracy: 0.260000\n",
      "Loss: 2.222873, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.211413, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.248397, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.154008, Train accuracy: 0.245667, val accuracy: 0.251000\n",
      "Loss: 2.138793, Train accuracy: 0.283889, val accuracy: 0.293000\n",
      "Loss: 2.003835, Train accuracy: 0.382667, val accuracy: 0.391000\n",
      "Loss: 1.563054, Train accuracy: 0.443222, val accuracy: 0.428000\n",
      "Loss: 1.667721, Train accuracy: 0.503778, val accuracy: 0.509000\n",
      "Loss: 1.695367, Train accuracy: 0.554000, val accuracy: 0.551000\n",
      "Loss: 1.504411, Train accuracy: 0.592333, val accuracy: 0.604000\n",
      "Loss: 1.105799, Train accuracy: 0.619111, val accuracy: 0.606000\n",
      "Loss: 1.362187, Train accuracy: 0.645889, val accuracy: 0.633000\n",
      "Loss: 1.383165, Train accuracy: 0.666667, val accuracy: 0.661000\n",
      "Loss: 1.107201, Train accuracy: 0.696444, val accuracy: 0.677000\n",
      "Loss: 1.095007, Train accuracy: 0.694667, val accuracy: 0.684000\n",
      "Loss: 1.045947, Train accuracy: 0.708111, val accuracy: 0.685000\n",
      "Loss: 2.220203, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.278606, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.174421, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.373389, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.184907, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.285046, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.164017, Train accuracy: 0.227222, val accuracy: 0.235000\n",
      "Loss: 2.003702, Train accuracy: 0.261000, val accuracy: 0.263000\n",
      "Loss: 2.076141, Train accuracy: 0.280889, val accuracy: 0.278000\n",
      "Loss: 1.845532, Train accuracy: 0.322444, val accuracy: 0.328000\n",
      "Loss: 1.323320, Train accuracy: 0.373222, val accuracy: 0.380000\n",
      "Loss: 1.754392, Train accuracy: 0.414333, val accuracy: 0.404000\n",
      "Loss: 1.822758, Train accuracy: 0.439556, val accuracy: 0.428000\n",
      "Loss: 1.390308, Train accuracy: 0.478333, val accuracy: 0.478000\n",
      "Loss: 1.443718, Train accuracy: 0.511889, val accuracy: 0.505000\n",
      "Loss: 1.425235, Train accuracy: 0.544778, val accuracy: 0.542000\n",
      "Loss: 2.256242, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.238954, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.289502, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.243391, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.169900, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.215769, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.177806, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.247847, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.049420, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.307870, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.121517, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.138464, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.277622, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.074701, Train accuracy: 0.217778, val accuracy: 0.224000\n",
      "Loss: 2.285249, Train accuracy: 0.238444, val accuracy: 0.243000\n",
      "Loss: 2.204494, Train accuracy: 0.252222, val accuracy: 0.251000\n",
      "Loss: 2.183301, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.177296, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.309061, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.177910, Train accuracy: 0.262222, val accuracy: 0.265000\n",
      "Loss: 2.063086, Train accuracy: 0.299889, val accuracy: 0.307000\n",
      "Loss: 1.634006, Train accuracy: 0.387000, val accuracy: 0.386000\n",
      "Loss: 1.636901, Train accuracy: 0.455778, val accuracy: 0.450000\n",
      "Loss: 1.646340, Train accuracy: 0.519556, val accuracy: 0.507000\n",
      "Loss: 1.405374, Train accuracy: 0.577444, val accuracy: 0.550000\n",
      "Loss: 1.315833, Train accuracy: 0.623889, val accuracy: 0.618000\n",
      "Loss: 1.497205, Train accuracy: 0.651222, val accuracy: 0.635000\n",
      "Loss: 1.506314, Train accuracy: 0.666222, val accuracy: 0.651000\n",
      "Loss: 1.110287, Train accuracy: 0.684444, val accuracy: 0.659000\n",
      "Loss: 0.953904, Train accuracy: 0.707889, val accuracy: 0.684000\n",
      "Loss: 1.010119, Train accuracy: 0.693778, val accuracy: 0.669000\n",
      "Loss: 0.801383, Train accuracy: 0.728778, val accuracy: 0.693000\n",
      "Loss: 2.266577, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.208027, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.363527, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.289554, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.213508, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.188802, Train accuracy: 0.196778, val accuracy: 0.206000\n",
      "Loss: 2.138382, Train accuracy: 0.237889, val accuracy: 0.243000\n",
      "Loss: 2.278545, Train accuracy: 0.275889, val accuracy: 0.275000\n",
      "Loss: 2.020891, Train accuracy: 0.287778, val accuracy: 0.291000\n",
      "Loss: 1.790269, Train accuracy: 0.336556, val accuracy: 0.335000\n",
      "Loss: 1.682337, Train accuracy: 0.381000, val accuracy: 0.386000\n",
      "Loss: 1.672486, Train accuracy: 0.419000, val accuracy: 0.413000\n",
      "Loss: 1.638248, Train accuracy: 0.470889, val accuracy: 0.456000\n",
      "Loss: 1.605195, Train accuracy: 0.510556, val accuracy: 0.496000\n",
      "Loss: 1.279192, Train accuracy: 0.535556, val accuracy: 0.535000\n",
      "Loss: 1.338175, Train accuracy: 0.564222, val accuracy: 0.550000\n",
      "Loss: 2.246372, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.282482, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.099364, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.308995, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.241692, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.223495, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.230999, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.191468, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.192906, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.107942, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.194164, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.186640, Train accuracy: 0.197000, val accuracy: 0.206000\n",
      "Loss: 2.246975, Train accuracy: 0.217444, val accuracy: 0.224000\n",
      "Loss: 2.303312, Train accuracy: 0.242111, val accuracy: 0.246000\n",
      "Loss: 2.100915, Train accuracy: 0.256333, val accuracy: 0.254000\n",
      "Loss: 2.174440, Train accuracy: 0.268111, val accuracy: 0.269000\n",
      "Loss: 2.207625, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.269724, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.251943, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.118921, Train accuracy: 0.255000, val accuracy: 0.250000\n",
      "Loss: 2.024305, Train accuracy: 0.277444, val accuracy: 0.282000\n",
      "Loss: 1.859950, Train accuracy: 0.327111, val accuracy: 0.336000\n",
      "Loss: 1.681025, Train accuracy: 0.393556, val accuracy: 0.399000\n",
      "Loss: 1.719208, Train accuracy: 0.468889, val accuracy: 0.463000\n",
      "Loss: 1.488270, Train accuracy: 0.521556, val accuracy: 0.516000\n",
      "Loss: 1.275046, Train accuracy: 0.564667, val accuracy: 0.554000\n",
      "Loss: 1.357891, Train accuracy: 0.601333, val accuracy: 0.581000\n",
      "Loss: 1.092856, Train accuracy: 0.632778, val accuracy: 0.615000\n",
      "Loss: 1.416399, Train accuracy: 0.661333, val accuracy: 0.643000\n",
      "Loss: 0.993478, Train accuracy: 0.673667, val accuracy: 0.652000\n",
      "Loss: 0.873414, Train accuracy: 0.685667, val accuracy: 0.672000\n",
      "Loss: 1.224678, Train accuracy: 0.689778, val accuracy: 0.668000\n",
      "Loss: 2.245617, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.192361, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.161206, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.343417, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.291757, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.282188, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.146915, Train accuracy: 0.204222, val accuracy: 0.210000\n",
      "Loss: 2.100175, Train accuracy: 0.250222, val accuracy: 0.250000\n",
      "Loss: 2.036670, Train accuracy: 0.269333, val accuracy: 0.270000\n",
      "Loss: 1.844154, Train accuracy: 0.297667, val accuracy: 0.300000\n",
      "Loss: 1.820080, Train accuracy: 0.328889, val accuracy: 0.334000\n",
      "Loss: 1.663778, Train accuracy: 0.373444, val accuracy: 0.374000\n",
      "Loss: 1.662306, Train accuracy: 0.415222, val accuracy: 0.406000\n",
      "Loss: 2.031961, Train accuracy: 0.437222, val accuracy: 0.421000\n",
      "Loss: 1.497171, Train accuracy: 0.466444, val accuracy: 0.440000\n",
      "Loss: 1.690137, Train accuracy: 0.497667, val accuracy: 0.473000\n",
      "Loss: 2.253379, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.304707, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.250180, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.269878, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.183550, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.202070, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.262423, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.130098, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.299549, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.174622, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.229479, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.042163, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.107098, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.106745, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.001008, Train accuracy: 0.218222, val accuracy: 0.220000\n",
      "Loss: 2.117746, Train accuracy: 0.239778, val accuracy: 0.242000\n",
      "Loss: 2.291901, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.171644, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.258246, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.014124, Train accuracy: 0.255667, val accuracy: 0.254000\n",
      "Loss: 1.995667, Train accuracy: 0.285333, val accuracy: 0.287000\n",
      "Loss: 1.849803, Train accuracy: 0.361333, val accuracy: 0.375000\n",
      "Loss: 1.607820, Train accuracy: 0.455889, val accuracy: 0.430000\n",
      "Loss: 1.592904, Train accuracy: 0.513444, val accuracy: 0.509000\n",
      "Loss: 1.299841, Train accuracy: 0.572556, val accuracy: 0.568000\n",
      "Loss: 1.103045, Train accuracy: 0.611556, val accuracy: 0.587000\n",
      "Loss: 1.311485, Train accuracy: 0.645111, val accuracy: 0.615000\n",
      "Loss: 0.868433, Train accuracy: 0.667333, val accuracy: 0.651000\n",
      "Loss: 1.084328, Train accuracy: 0.683667, val accuracy: 0.657000\n",
      "Loss: 0.693726, Train accuracy: 0.691889, val accuracy: 0.680000\n",
      "Loss: 1.178536, Train accuracy: 0.720111, val accuracy: 0.694000\n",
      "Loss: 1.081882, Train accuracy: 0.711111, val accuracy: 0.686000\n",
      "Loss: 2.237595, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.176968, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.238168, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.306040, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.160561, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.227788, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.142045, Train accuracy: 0.216444, val accuracy: 0.224000\n",
      "Loss: 2.143930, Train accuracy: 0.250556, val accuracy: 0.248000\n",
      "Loss: 2.038902, Train accuracy: 0.275667, val accuracy: 0.286000\n",
      "Loss: 1.971141, Train accuracy: 0.300111, val accuracy: 0.306000\n",
      "Loss: 1.643518, Train accuracy: 0.355667, val accuracy: 0.358000\n",
      "Loss: 1.756769, Train accuracy: 0.407333, val accuracy: 0.404000\n",
      "Loss: 1.704650, Train accuracy: 0.437889, val accuracy: 0.436000\n",
      "Loss: 1.388563, Train accuracy: 0.475556, val accuracy: 0.482000\n",
      "Loss: 1.554973, Train accuracy: 0.510222, val accuracy: 0.501000\n",
      "Loss: 1.433569, Train accuracy: 0.547667, val accuracy: 0.547000\n",
      "Loss: 2.274969, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.228169, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.267637, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.161315, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.262156, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.187020, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.139080, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.175797, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.229081, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.243539, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.156101, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.047956, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.093165, Train accuracy: 0.199000, val accuracy: 0.207000\n",
      "Loss: 2.162947, Train accuracy: 0.222556, val accuracy: 0.226000\n",
      "Loss: 2.122275, Train accuracy: 0.247778, val accuracy: 0.247000\n",
      "Loss: 2.103696, Train accuracy: 0.260444, val accuracy: 0.260000\n",
      "Loss: 2.234484, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.239550, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.283034, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.065646, Train accuracy: 0.265333, val accuracy: 0.261000\n",
      "Loss: 1.932273, Train accuracy: 0.316333, val accuracy: 0.319000\n",
      "Loss: 1.770556, Train accuracy: 0.406556, val accuracy: 0.399000\n",
      "Loss: 1.416735, Train accuracy: 0.483556, val accuracy: 0.474000\n",
      "Loss: 1.288267, Train accuracy: 0.556333, val accuracy: 0.549000\n",
      "Loss: 1.263103, Train accuracy: 0.601778, val accuracy: 0.587000\n",
      "Loss: 1.052034, Train accuracy: 0.638667, val accuracy: 0.615000\n",
      "Loss: 1.488378, Train accuracy: 0.670111, val accuracy: 0.652000\n",
      "Loss: 1.237388, Train accuracy: 0.696333, val accuracy: 0.676000\n",
      "Loss: 0.956222, Train accuracy: 0.703111, val accuracy: 0.693000\n",
      "Loss: 0.977038, Train accuracy: 0.710222, val accuracy: 0.698000\n",
      "Loss: 0.842875, Train accuracy: 0.735111, val accuracy: 0.694000\n",
      "Loss: 0.675859, Train accuracy: 0.747556, val accuracy: 0.697000\n",
      "Loss: 2.215086, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.223091, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.261983, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.283624, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.092124, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.163673, Train accuracy: 0.200000, val accuracy: 0.211000\n",
      "Loss: 2.061591, Train accuracy: 0.249111, val accuracy: 0.251000\n",
      "Loss: 2.089511, Train accuracy: 0.271889, val accuracy: 0.273000\n",
      "Loss: 2.102047, Train accuracy: 0.291444, val accuracy: 0.295000\n",
      "Loss: 1.909914, Train accuracy: 0.335000, val accuracy: 0.335000\n",
      "Loss: 1.787311, Train accuracy: 0.390111, val accuracy: 0.388000\n",
      "Loss: 1.697422, Train accuracy: 0.423667, val accuracy: 0.414000\n",
      "Loss: 1.488492, Train accuracy: 0.468889, val accuracy: 0.470000\n",
      "Loss: 1.310191, Train accuracy: 0.502556, val accuracy: 0.492000\n",
      "Loss: 1.476528, Train accuracy: 0.543000, val accuracy: 0.540000\n",
      "Loss: 1.173065, Train accuracy: 0.576889, val accuracy: 0.576000\n",
      "Loss: 2.268945, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.234365, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.273195, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.207427, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.135253, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.173859, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.139690, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.059375, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.083657, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.295270, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.147408, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.140342, Train accuracy: 0.197444, val accuracy: 0.206000\n",
      "Loss: 2.149057, Train accuracy: 0.221667, val accuracy: 0.227000\n",
      "Loss: 2.053624, Train accuracy: 0.250000, val accuracy: 0.253000\n",
      "Loss: 2.010087, Train accuracy: 0.264333, val accuracy: 0.263000\n",
      "Loss: 2.158522, Train accuracy: 0.273667, val accuracy: 0.271000\n",
      "Loss: 2.283951, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.282379, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.269159, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.218774, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.246436, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.256915, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.283539, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.176415, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.173778, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.246600, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.333755, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.354457, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.278174, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.212029, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.102715, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.181745, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.296714, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.303802, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.299472, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.260393, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.250588, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.211761, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.266960, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.221194, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.275187, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.209559, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.268467, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.320740, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.196235, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.205766, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.330885, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.220776, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.301370, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.297320, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.296096, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.293671, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.271320, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.278860, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.286420, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.245780, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.259260, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.243034, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.269580, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.237208, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.227980, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.266768, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.263559, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.228705, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.285636, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.281131, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.252092, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.236748, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.286787, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.176818, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.263263, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.183058, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.186952, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.241077, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.161279, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.241971, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.275899, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.196071, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.259239, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.234188, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.292963, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.293069, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.273359, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.269813, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.283196, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.298502, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.229601, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.284423, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.315284, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.244273, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.239462, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.205782, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.255098, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.282939, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.243221, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.246381, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.298484, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.296737, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.282316, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.280291, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.285415, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.264137, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.281023, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.254727, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.278102, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.288551, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.268925, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.288643, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.243274, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.278888, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.250802, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.288211, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.279311, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.266145, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.240172, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.266815, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.230061, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.253467, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.235091, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.314409, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.206718, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.198454, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.212763, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.183431, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.157361, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.190006, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.131776, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.195619, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.289888, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.286211, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.262871, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.260281, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.260925, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.249276, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.228125, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.193863, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.237341, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.264823, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.240755, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.212881, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.178474, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.220992, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.234860, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.324198, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.301130, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.294210, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.300100, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.295654, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.294491, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.257986, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.257117, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.247346, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.251102, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.237208, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.295298, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.243552, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.294063, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.255181, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.260887, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.219376, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.295413, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.258084, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.250511, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.270384, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.242213, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.179962, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.293621, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.233703, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.238728, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.332103, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.228872, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.237296, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.161768, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.213090, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.218420, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.177918, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.296814, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.270175, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.273544, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.258702, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.259006, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.277974, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.319153, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.257822, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.224968, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.267188, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.295161, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.263217, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.178167, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.250317, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.240076, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.296727, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.298870, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.290498, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.284652, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.275589, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.262233, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.293306, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.286830, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.321570, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.253332, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.237648, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.270419, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.257392, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.264386, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.280141, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.250962, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.260635, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.277021, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.271381, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.281477, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.248917, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.238296, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.278457, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.219732, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.242480, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.254718, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.203766, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.218411, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.226206, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.228531, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.214523, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.300785, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.277152, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.291492, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.279853, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.283024, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.255503, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.260121, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.264023, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.254264, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.265906, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.223508, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.235406, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.294597, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.194764, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.194664, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.209117, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.197909, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.256678, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.297402, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.290263, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.297484, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.277031, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.269835, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.268724, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.257391, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.263645, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.265097, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.266409, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.269224, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.266589, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.229215, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.230484, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.262293, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.247360, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.302045, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.278074, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.270235, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.286965, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.262623, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.223676, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.266098, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.201323, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.162511, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.236806, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.117189, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.235044, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.179776, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.221911, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.245193, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.199975, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.293088, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.288669, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.269682, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.279316, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.256216, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.249838, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.244818, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.206351, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.256529, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.238441, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.254654, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.204213, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.299181, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.210192, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.242710, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.265997, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.305105, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.289582, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.283280, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.278169, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.263839, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.267205, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.258157, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.258838, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.302571, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.243163, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.237242, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.242086, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.244986, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.254337, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.269488, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "Loss: 2.265522, Train accuracy: 0.196667, val accuracy: 0.206000\n",
      "best validation accuracy achieved: 0.735000\n"
     ]
    }
   ],
   "source": [
    "# Let's train the best one-hidden-layer network we can\n",
    "\n",
    "learning_rates = [1e-1, 1e-2, 1e-3]\n",
    "reg_strength = [1e-3, 1e-5]\n",
    "learning_rate_decay = 0.999\n",
    "hidden_layer_size = [32, 64, 128]\n",
    "num_epochs = 16\n",
    "batch_size = [64, 128, 256]\n",
    "\n",
    "best_classifier = None\n",
    "best_val_accuracy = 0\n",
    "\n",
    "loss_history = []\n",
    "train_history = []\n",
    "val_history = []\n",
    "\n",
    "# TODO find the best hyperparameters to train the network\n",
    "# Don't hesitate to add new values to the arrays above, perform experiments, use any tricks you want\n",
    "# You should expect to get to at least 40% of valudation accuracy\n",
    "# Save loss/train/history of the best classifier to the variables above\n",
    "\n",
    "dataset = Dataset(train_X, train_y, val_X, val_y)\n",
    "\n",
    "for lr in learning_rates:\n",
    "    for rs in reg_strength:\n",
    "        for ls in hidden_layer_size:\n",
    "            for bs in batch_size:\n",
    "                model = TwoLayerNet(n_input=train_X.shape[1], n_output=10, hidden_layer_size=ls, reg=rs)\n",
    "                trainer = Trainer(model, dataset, MomentumSGD(), learning_rate=lr, num_epochs=num_epochs, batch_size=bs)\n",
    "                temp_loss_history, temp_train_history, temp_val_history = trainer.fit()\n",
    "                \n",
    "                if temp_val_history[-1] > best_val_accuracy:\n",
    "                    best_classifier = model\n",
    "                    best_val_accuracy = temp_val_history[-1]\n",
    "                    loss_history = temp_loss_history.copy()\n",
    "                    train_history = temp_train_history.copy()\n",
    "                    val_history = temp_val_history.copy()\n",
    "\n",
    "print('best validation accuracy achieved: %f' % best_val_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x27026840cd0>]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x700 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(15, 7))\n",
    "plt.subplot(211)\n",
    "plt.title(\"Loss\")\n",
    "plt.plot(loss_history)\n",
    "plt.subplot(212)\n",
    "plt.title(\"Train/validation accuracy\")\n",
    "plt.plot(train_history)\n",
    "plt.plot(val_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Как обычно, посмотрим, как наша лучшая модель работает на тестовых данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural net test set accuracy: 0.687000\n"
     ]
    }
   ],
   "source": [
    "test_pred = best_classifier.predict(test_X)\n",
    "test_accuracy = multiclass_accuracy(test_pred, test_y)\n",
    "print('Neural net test set accuracy: %f' % (test_accuracy, ))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
